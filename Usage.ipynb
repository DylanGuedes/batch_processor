{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = \"http://localhost:4545\"\n",
    "api_endpoint = \"/api\"\n",
    "url=host+api_endpoint\n",
    "params = {\n",
    "    \"capability\": \"house_pricing\",\n",
    "    \"house_pricing_schema\": {\n",
    "        \"street\": \"string\",\n",
    "        \"zip\": \"integer\",\n",
    "        \"beds\": \"integer\",\n",
    "        \"baths\": \"integer\",\n",
    "        \"sq__ft\": \"integer\",\n",
    "        \"type\": \"string\",\n",
    "        \"price\": \"integer\",\n",
    "        \"sale_date\": \"string\",\n",
    "        \"date\": \"string\"\n",
    "    },\n",
    "    \"publish_strategy\": {\n",
    "        \"name\": \"file\",\n",
    "        \"format\": \"csv\",\n",
    "        \"path\": \"/tmp/data/lr_model.csv\"\n",
    "    },\n",
    "    \"features\": [\"baths\",\"beds\",\"sq__ft\"],\n",
    "    \"job\": \"linear_regression\",\n",
    "    \"label_col\": \"price\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = \"/register_job\"\n",
    "r = requests.post(url+endpoint, json=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_uuid = r.json()['job_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'78c2aaf1-99ff-4772-a62f-701241464fd1'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = \"/start_job\"\n",
    "r = requests.get(url+endpoint, params={'job_id': job_uuid })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{}'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_log(uuid):\n",
    "    endpoint = \"/retrieve_log\"\n",
    "    r = requests.get(url+endpoint, params={'job_id': uuid})\n",
    "    return r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylog = list_log(job_uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-01 16:03:13 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "/usr/lib/python3.4/importlib/_bootstrap.py:321: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "add field street of type string\n",
      "add field zip of type integer\n",
      "add field sale_date of type string\n",
      "add field price of type integer\n",
      "add field baths of type integer\n",
      "add field date of type string\n",
      "add field type of type string\n",
      "add field sq__ft of type integer\n",
      "add field beds of type integer\n",
      "2018-08-01 16:03:13 INFO  SparkContext:54 - Running Spark version 2.3.0\n",
      "2018-08-01 16:03:13 INFO  SparkContext:54 - Submitted application: linear_regression.py\n",
      "2018-08-01 16:03:13 INFO  SecurityManager:54 - Changing view acls to: root\n",
      "2018-08-01 16:03:13 INFO  SecurityManager:54 - Changing modify acls to: root\n",
      "2018-08-01 16:03:13 INFO  SecurityManager:54 - Changing view acls groups to: \n",
      "2018-08-01 16:03:13 INFO  SecurityManager:54 - Changing modify acls groups to: \n",
      "2018-08-01 16:03:13 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\n",
      "2018-08-01 16:03:13 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 39715.\n",
      "2018-08-01 16:03:14 INFO  SparkEnv:54 - Registering MapOutputTracker\n",
      "2018-08-01 16:03:14 INFO  SparkEnv:54 - Registering BlockManagerMaster\n",
      "2018-08-01 16:03:14 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "2018-08-01 16:03:14 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up\n",
      "2018-08-01 16:03:14 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-0652c057-6c00-496e-b5f1-56f5563412e1\n",
      "2018-08-01 16:03:14 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB\n",
      "2018-08-01 16:03:14 INFO  SparkEnv:54 - Registering OutputCommitCoordinator\n",
      "2018-08-01 16:03:14 INFO  log:192 - Logging initialized @1895ms\n",
      "2018-08-01 16:03:14 INFO  Server:346 - jetty-9.3.z-SNAPSHOT\n",
      "2018-08-01 16:03:14 INFO  Server:414 - Started @1968ms\n",
      "2018-08-01 16:03:14 INFO  AbstractConnector:278 - Started ServerConnector@23c2f74c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}\n",
      "2018-08-01 16:03:14 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.\n",
      "2018-08-01 16:03:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6d8284ea{/jobs,null,AVAILABLE,@Spark}\n",
      "2018-08-01 16:03:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f6795ca{/jobs/json,null,AVAILABLE,@Spark}\n",
      "2018-08-01 16:03:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@12b04c46{/jobs/job,null,AVAILABLE,@Spark}\n",
      "2018-08-01 16:03:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4125dd26{/jobs/job/json,null,AVAILABLE,@Spark}\n",
      "2018-08-01 16:03:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@228fc90d{/stages,null,AVAILABLE,@Spark}\n",
      "2018-08-01 16:03:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@324d7366{/stages/json,null,AVAILABLE,@Spark}\n",
      "2018-08-01 16:03:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2992d179{/stages/stage,null,AVAILABLE,@Spark}\n",
      "2018-08-01 16:03:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@43a50d8a{/stages/stage/json,null,AVAILABLE,@Spark}\n",
      "2018-08-01 16:03:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7c83059e{/stages/pool,null,AVAILABLE,@Spark}\n",
      "2018-08-01 16:03:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@35d7726b{/stages/pool/json,null,AVAILABLE,@Spark}\n",
      "2018-08-01 16:03:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7becca70{/storage,null,AVAILABLE,@Spark}\n",
      "2018-08-01 16:03:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@104e51da{/storage/json,null,AVAILABLE,@Spark}\n",
      "2018-08-01 16:03:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@748509b8{/storage/rdd,null,AVAILABLE,@Spark}\n",
      "2018-08-01 16:03:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7acf6969{/storage/rdd/json,null,AVAILABLE,@Spark}\n",
      "2018-08-01 16:03:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@676d930a{/environment,null,AVAILABLE,@Spark}\n",
      "2018-08-01 16:03:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5cfdebc{/environment/json,null,AVAILABLE,@Spark}\n",
      "2018-08-01 16:03:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@595bdf74{/executors,null,AVAILABLE,@Spark}\n",
      "2018-08-01 16:03:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@58de7117{/executors/json,null,AVAILABLE,@Spark}\n",
      "2018-08-01 16:03:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@53204cc5{/executors/threadDump,null,AVAILABLE,@Spark}\n",
      "2018-08-01 16:03:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@28614223{/executors/threadDump/json,null,AVAILABLE,@Spark}\n",
      "2018-08-01 16:03:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2f469824{/static,null,AVAILABLE,@Spark}\n",
      "2018-08-01 16:03:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@57c62881{/,null,AVAILABLE,@Spark}\n",
      "2018-08-01 16:03:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@74dc4abb{/api,null,AVAILABLE,@Spark}\n",
      "2018-08-01 16:03:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61850aa1{/jobs/job/kill,null,AVAILABLE,@Spark}\n",
      "2018-08-01 16:03:14 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7ca3422a{/stages/stage/kill,null,AVAILABLE,@Spark}\n",
      "2018-08-01 16:03:14 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://localhost:4040\n",
      "2018-08-01 16:03:14 INFO  SparkContext:54 - Added file file:/jobs/linear_regression.py at spark://master:39715/files/linear_regression.py with timestamp 1533139394612\n",
      "2018-08-01 16:03:14 INFO  Utils:54 - Copying /jobs/linear_regression.py to /tmp/spark-161e2987-217d-4bf3-ae9c-e8bd01fdb5ef/userFiles-dbe17a50-99ac-4a4c-8df8-68332ce12013/linear_regression.py\n",
      "2018-08-01 16:03:14 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://master:7077...\n",
      "2018-08-01 16:03:14 INFO  TransportClientFactory:267 - Successfully created connection to master/172.18.0.3:7077 after 35 ms (0 ms spent in bootstraps)\n",
      "2018-08-01 16:03:14 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20180801160314-0027\n",
      "2018-08-01 16:03:14 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20180801160314-0027/0 on worker-20180801123606-172.18.0.6-8881 (172.18.0.6:8881) with 2 core(s)\n",
      "2018-08-01 16:03:14 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20180801160314-0027/0 on hostPort 172.18.0.6:8881 with 2 core(s), 1024.0 MB RAM\n",
      "2018-08-01 16:03:14 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40985.\n",
      "2018-08-01 16:03:14 INFO  NettyBlockTransferService:54 - Server created on master:40985\n",
      "2018-08-01 16:03:14 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "2018-08-01 16:03:14 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, master, 40985, None)\n",
      "2018-08-01 16:03:14 INFO  BlockManagerMasterEndpoint:54 - Registering block manager master:40985 with 366.3 MB RAM, BlockManagerId(driver, master, 40985, None)\n",
      "2018-08-01 16:03:14 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, master, 40985, None)\n",
      "2018-08-01 16:03:14 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, master, 40985, None)\n",
      "2018-08-01 16:03:14 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20180801160314-0027/0 is now RUNNING\n",
      "2018-08-01 16:03:15 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7f9263e9{/metrics/json,null,AVAILABLE,@Spark}\n",
      "2018-08-01 16:03:15 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0\n",
      "########################################\n",
      "Model saved at /tmp/data/lr_model.csv\n",
      "########################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(eval(mylog))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"publish_strategy\":{\"name\":\"file\",\"format\":\"csv\"},\"job\":\"linear_regression\",\"car_monitoring_schema\":{\"kmh\":\"integer\"},\"capability\":\"car_monitoring\"}'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint = \"/retrieve_params\"\n",
    "r = requests.get(url+endpoint, params={'job_id': job_uuid})\n",
    "r.text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
